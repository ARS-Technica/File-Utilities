"""
A simple script to download every available issue of a single manga series hosted on https://w15.mangafreak.net. 
"""


import os
import time
from bs4 import BeautifulSoup
from tqdm import tqdm
import tkinter as tk
from tkinter import ttk
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

def get_manga_title(url):
    manga_title = url.split('/')[-1]
    manga_title = manga_title.replace("_", " ")
    return manga_title

def get_save_folder():
    folder_path = input("Enter the folder path where you want to save the manga files: ")
    folder_path = folder_path.strip()

    if not os.path.isdir(folder_path):
        print("Invalid folder path. Please provide a valid existing folder path.")
        return get_save_folder()

    return folder_path

def download_files(url, folder_path, progress_bar, driver):
    driver.get(url)
    time.sleep(5)  # Wait for page to load (adjust as needed)

    # Get the page source after JavaScript execution
    page_source = driver.page_source

    soup = BeautifulSoup(page_source, 'html.parser')
    all_links = soup.find_all('a')

    # Filter links containing the word "Download"
    download_links = [link for link in all_links if 'Download' in link.text]

    for link in download_links:
        file_name = link.text.strip()
        file_name = file_name.replace("_", " ")

        file_url = link.get('href')
        if not file_url:
            continue

        with open(os.path.join(folder_path, file_name), 'wb') as file:
            driver.get(file_url)

            # Wait for the file to download (adjust as needed)
            time.sleep(10)

            # Save the file using Selenium's save_screenshot (you may need to customize this)
            driver.save_screenshot(os.path.join(folder_path, file_name))

        progress_bar.step(1)

def main():
    url = input("Enter the URL: ")

    if not url.startswith("https://w15.mangafreak.net"):
        print("Invalid URL. Please provide a valid MangaFreak URL.")
        return

    manga_title = get_manga_title(url)

    folder_path = get_save_folder()

    manga_folder = os.path.join(folder_path, manga_title.replace(" ", "_"))
    os.makedirs(manga_folder, exist_ok=True)

    root = tk.Tk()
    root.title("Manga Scraper Progress")

    overall_progress = tk.DoubleVar()
    overall_progress.set(0)

    overall_progress_bar = ttk.Progressbar(root, variable=overall_progress, maximum=100)
    overall_progress_bar.pack(pady=10)

    # Configure Chrome options for Selenium
    chrome_options = Options()
    chrome_options.add_argument("--headless")  # Run Chrome in headless mode (no GUI)
    driver = webdriver.Chrome(executable_path='/path/to/chromedriver')
    # Replace /path/to/chromedriver with the actual path to the ChromeDriver executable on your system.

    # Retry in case of issues (adjust as needed)
    max_retries = 5
    retries = 0

    while retries < max_retries:
        try:
            download_files(url, manga_folder, overall_progress_bar, driver)
            driver.quit()
            root.destroy()
            print("Manga Downloaded Successfully!")
            break
        except Exception as e:
            # Handle exceptions (e.g., CloudFlare challenges, network issues)
            print(f"Error: {e}")
            print("Retrying...")
            retries += 1
            time.sleep(5)  # Wait before retrying (adjust as needed)

    if retries >= max_retries:
        print("Max retries reached. Failed to download manga.")

if __name__ == "__main__":
    main()

